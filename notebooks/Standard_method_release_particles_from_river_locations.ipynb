{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d99176d",
   "metadata": {},
   "source": [
    "I need to figure out a way of translating the river mouth locations to the grid from the model. \n",
    "\n",
    "TOC:\n",
    "1. read shapefiles (Lebreton or Meijer)\n",
    "2. split Point objects.\n",
    "3. bin the rivers into the coastal cells\n",
    "4. Cluster the rivers in N groups\n",
    "5. generate initial conditions for cluster\n",
    "    - save the river coord inside the cluster\n",
    "    - generate delayed realease randomized\n",
    "    - save them, sneaky beasts\n",
    "6. Compute priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f270058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance_two(point_A, point_B):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "    \"\"\"\n",
    "    lat1, lon1 = point_A\n",
    "    lat2, lon2 = point_B\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "\n",
    "def region_filters(DF, lon_min, lon_max, lat_min, lat_max, shapefile=False):\n",
    "    \"\"\"\n",
    "    DF is the River_sources dataframes. lat_min, lat_max, lon_min, lon_max are the domain limits.\n",
    "    Returns the dataframe only for the region.\n",
    "    \"\"\"\n",
    "    if shapefile:\n",
    "        X = DF.geometry.x\n",
    "        Y = DF.geometry.y\n",
    "    else:\n",
    "        X = DF['X']\n",
    "        Y = DF['Y']\n",
    "        \n",
    "    mask = (X <= lon_max) & (X > lon_min) & (Y <= lat_max) & (Y > lat_min)\n",
    "    \n",
    "    new_DF = DF[mask]\n",
    "    return new_DF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecca60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coastal_fields = xr.load_dataset('../coastal_fields.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d53c453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast = coastal_fields.coast.values\n",
    "lats = coastal_fields.lat.values\n",
    "lons = coastal_fields.lon.values\n",
    "\n",
    "X = coastal_fields.lon_mesh\n",
    "Y = coastal_fields.lat_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "iy_coast, ix_coast = np.where(coast==1)\n",
    "lat_coast = lats[iy_coast]\n",
    "lon_coast = lons[ix_coast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acc9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_coastal_cell(latidute, longitude, coord_lat, coord_lon):    \n",
    "    \"\"\"\n",
    "    Function to find the index of the closest point to a certain lon/lat value.\n",
    "    \n",
    "    latidute and longitude are the dimensinal 1D arrays of the grid, with the same length.\n",
    "    coord_lat and coord_lon are the coordinates of a point.\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = np.sqrt((longitude-coord_lon)**2 + (latidute-coord_lat)**2)                     \n",
    "    index = distance.argmin()               \n",
    "        \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20e1a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_coastal_cell(lat_coast, lon_coast, -10, -30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6142e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "South_Atlantic_region = (-70, 25, -50, -5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464ba358",
   "metadata": {},
   "source": [
    "# 1. Loading data from GIS shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3cee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_geopandas2pandas(geoDF):\n",
    "    '''Replaces the geometry column with a X and Y columns\n",
    "    There no built-in function for this in geopandas! \n",
    "    '''\n",
    "    \n",
    "    L = len(geoDF)\n",
    "    coord = np.zeros((L,2))\n",
    "    coord[:, 0] = geoDF.geometry.x\n",
    "    coord[:, 1] = geoDF.geometry.y\n",
    "    aux = pd.DataFrame(coord, columns=['X','Y'])\n",
    "    geoDF.drop(columns=['geometry'], inplace=True)\n",
    "    geoDF = pd.concat([geoDF, aux], axis=1)\n",
    "    \n",
    "    return geoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c918dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/sources/Lebreton_rivers/PlasticRiverInputs/' \n",
    "lebreton = convert_geopandas2pandas(gpd.read_file(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d46aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_mid</th>\n",
       "      <th>i_low</th>\n",
       "      <th>i_high</th>\n",
       "      <th>i_mid_jan</th>\n",
       "      <th>i_low_jan</th>\n",
       "      <th>i_high_jan</th>\n",
       "      <th>i_mid_feb</th>\n",
       "      <th>i_low_feb</th>\n",
       "      <th>i_high_feb</th>\n",
       "      <th>i_mid_mar</th>\n",
       "      <th>...</th>\n",
       "      <th>runoff_jul</th>\n",
       "      <th>runoff_aug</th>\n",
       "      <th>runoff_sep</th>\n",
       "      <th>runoff_oct</th>\n",
       "      <th>runoff_nov</th>\n",
       "      <th>runoff_dec</th>\n",
       "      <th>mpw</th>\n",
       "      <th>area</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21753.3</td>\n",
       "      <td>22500000.0</td>\n",
       "      <td>9.812500</td>\n",
       "      <td>37.329167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.117503</td>\n",
       "      <td>0.046447</td>\n",
       "      <td>0.431570</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.033584</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.089840</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172272</td>\n",
       "      <td>0.075899</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>0.176044</td>\n",
       "      <td>0.588417</td>\n",
       "      <td>0.466081</td>\n",
       "      <td>506114.0</td>\n",
       "      <td>95100000.0</td>\n",
       "      <td>9.387500</td>\n",
       "      <td>37.254167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236187</td>\n",
       "      <td>0.135462</td>\n",
       "      <td>0.101813</td>\n",
       "      <td>0.223936</td>\n",
       "      <td>0.821796</td>\n",
       "      <td>0.500808</td>\n",
       "      <td>56294.6</td>\n",
       "      <td>33500000.0</td>\n",
       "      <td>9.804167</td>\n",
       "      <td>37.237500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163098</td>\n",
       "      <td>0.065719</td>\n",
       "      <td>0.586740</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.070142</td>\n",
       "      <td>0.041209</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.141035</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275328</td>\n",
       "      <td>0.182635</td>\n",
       "      <td>0.184765</td>\n",
       "      <td>0.335541</td>\n",
       "      <td>1.101117</td>\n",
       "      <td>0.927117</td>\n",
       "      <td>349409.0</td>\n",
       "      <td>99200000.0</td>\n",
       "      <td>9.229167</td>\n",
       "      <td>37.220833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>0.150693</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>0.033372</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200378</td>\n",
       "      <td>0.105010</td>\n",
       "      <td>0.099647</td>\n",
       "      <td>0.219543</td>\n",
       "      <td>0.728243</td>\n",
       "      <td>0.591818</td>\n",
       "      <td>199000.0</td>\n",
       "      <td>39700000.0</td>\n",
       "      <td>9.254167</td>\n",
       "      <td>37.220833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      i_mid     i_low    i_high  i_mid_jan  i_low_jan  i_high_jan  i_mid_feb  \\\n",
       "0  0.000000  0.000000  0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "1  0.117503  0.046447  0.431570   0.008847   0.003387    0.033584   0.025464   \n",
       "2  0.004653  0.001518  0.021067   0.000364   0.000116    0.001692   0.000750   \n",
       "3  0.163098  0.065719  0.586740   0.019418   0.007780    0.070142   0.041209   \n",
       "4  0.038200  0.014144  0.150693   0.003528   0.001281    0.014193   0.008848   \n",
       "\n",
       "   i_low_feb  i_high_feb  i_mid_mar  ...  runoff_jul  runoff_aug  runoff_sep  \\\n",
       "0   0.000000    0.000000   0.000000  ...    0.000000    0.000000    0.000000   \n",
       "1   0.010425    0.089840   0.022978  ...    0.172272    0.075899    0.067729   \n",
       "2   0.000250    0.003305   0.000905  ...    0.236187    0.135462    0.101813   \n",
       "3   0.017347    0.141035   0.030320  ...    0.275328    0.182635    0.184765   \n",
       "4   0.003407    0.033372   0.007342  ...    0.200378    0.105010    0.099647   \n",
       "\n",
       "   runoff_oct  runoff_nov  runoff_dec       mpw        area         X  \\\n",
       "0    0.000000    0.000000    0.000000   21753.3  22500000.0  9.812500   \n",
       "1    0.176044    0.588417    0.466081  506114.0  95100000.0  9.387500   \n",
       "2    0.223936    0.821796    0.500808   56294.6  33500000.0  9.804167   \n",
       "3    0.335541    1.101117    0.927117  349409.0  99200000.0  9.229167   \n",
       "4    0.219543    0.728243    0.591818  199000.0  39700000.0  9.254167   \n",
       "\n",
       "           Y  \n",
       "0  37.329167  \n",
       "1  37.254167  \n",
       "2  37.237500  \n",
       "3  37.220833  \n",
       "4  37.220833  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lebreton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf9aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/sources/Meijer2021_midpoint_emissions/' \n",
    "meijer = convert_geopandas2pandas(gpd.read_file(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c98ea534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dots_exten</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164904</td>\n",
       "      <td>168.797917</td>\n",
       "      <td>-46.580833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124932</td>\n",
       "      <td>168.348750</td>\n",
       "      <td>-46.447083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.213370</td>\n",
       "      <td>168.337083</td>\n",
       "      <td>-46.418750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121138</td>\n",
       "      <td>168.021250</td>\n",
       "      <td>-46.357917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197533</td>\n",
       "      <td>169.811250</td>\n",
       "      <td>-46.343750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dots_exten           X          Y\n",
       "0    0.164904  168.797917 -46.580833\n",
       "1    0.124932  168.348750 -46.447083\n",
       "2    1.213370  168.337083 -46.418750\n",
       "3    0.121138  168.021250 -46.357917\n",
       "4    0.197533  169.811250 -46.343750"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meijer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd346b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meijer.rename(columns={'dots_exten':'Discharge(MT/year)'}, inplace=True)\n",
    "meijer.to_csv('../data/sources/Meijer2021_midpoint_emissions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564cdfe",
   "metadata": {},
   "source": [
    "# 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31eebb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rivers2coastalgrid(DF, coastal_fields):\n",
    "    \n",
    "    N = len(DF)\n",
    "    \n",
    "    coast = coastal_fields.coast.values\n",
    "    lats = coastal_fields.lat.values\n",
    "    lons = coastal_fields.lon.values\n",
    "    iy_coast, ix_coast = np.where(coast==1)\n",
    "    lat_coast = lats[iy_coast]\n",
    "    lon_coast = lons[ix_coast]\n",
    "\n",
    "    new_coordinates = np.zeros((N, 2)) \n",
    "\n",
    "    for i in range(N):\n",
    "        x_lon = DF.iloc[i].X\n",
    "        x_lat = DF.iloc[i].Y\n",
    "\n",
    "        n_index = nearest_coastal_cell(lat_coast, lon_coast, x_lat, x_lon)\n",
    "        new_coordinates[i,:] = (lon_coast[n_index], lat_coast[n_index])\n",
    "        \n",
    "    aux = pd.DataFrame(new_coordinates, columns=['X_bin', 'Y_bin'], index=DF.index)\n",
    "    new_DF = pd.concat([DF, aux], axis=1)\n",
    "    \n",
    "    counts = new_DF.groupby(['X_bin', 'Y_bin']).count().loc[:, 'X'].values\n",
    "    new_DF = new_DF.groupby(['X_bin', 'Y_bin']).sum()\n",
    "    new_DF['merged_rivers'] = counts\n",
    "    new_DF.reset_index(inplace=True)\n",
    "    new_DF.drop(labels=['X', 'Y'], axis=1, inplace=True)\n",
    "\n",
    "    return new_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad213757",
   "metadata": {},
   "source": [
    "We select a smaller region for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce07b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_lebreton = region_filters(lebreton, *South_Atlantic_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4730c79d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'coastal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4eb6b955de6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbin_lebreton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrivers2coastalgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_lebreton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoastal_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-b12eb0532171>\u001b[0m in \u001b[0;36mrivers2coastalgrid\u001b[0;34m(DF, coastal_fields)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcoast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoastal_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoastal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoastal_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoastal_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/py3_parcels/lib/python3.6/site-packages/xarray/core/common.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;34m\"{!r} object has no attribute {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'coastal'"
     ]
    }
   ],
   "source": [
    "bin_lebreton = rivers2coastalgrid(sa_lebreton, coastal_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d67a7e3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bin_lebreton' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e98fb40a13c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbin_lebreton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bin_lebreton' is not defined"
     ]
    }
   ],
   "source": [
    "bin_lebreton.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bf386",
   "metadata": {},
   "source": [
    "**The units are tons per year** or $10^3$ kg per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_meijer = region_filters(meijer, *South_Atlantic_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de74b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_meijer.sort_values(['dots_exten'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f162ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_meijer = rivers2coastalgrid(sa_meijer, coastal_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56188bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_meijer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797b3c3",
   "metadata": {},
   "source": [
    "implement a counter for the rivers merged per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent((-70, 25, -50, 0), crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "#ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.RIVERS)\n",
    "ax.gridlines(draw_labels=True, dms=False, x_inline=False, y_inline=False)\n",
    "\n",
    "#plt.pcolormesh(X, Y, coast)\n",
    "im = plt.scatter(bin_lebreton['X_bin'], bin_lebreton['Y_bin'], c=bin_lebreton['i_high'],\n",
    "                 s=bin_lebreton['i_high']/5, cmap='plasma', edgecolors=None)\n",
    "plt.colorbar(im)\n",
    "plt.title('Lebreton et al. 2018', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lebreton = bin_lebreton['i_high'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff18cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lebreton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent((-70, 25, -50, 0), crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "#ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.RIVERS)\n",
    "ax.gridlines(draw_labels=True, dms=False, x_inline=False, y_inline=False)\n",
    "\n",
    "#plt.pcolormesh(X, Y, coast)\n",
    "im = plt.scatter(bin_meijer['X_bin'], bin_meijer['Y_bin'], c=bin_meijer['dots_exten'],\n",
    "                 s=bin_meijer['dots_exten']/5, cmap='plasma', edgecolors=None)\n",
    "plt.colorbar(im)\n",
    "plt.title('Meijer al. 2021', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_meijer = bin_meijer['dots_exten'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_meijer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589aaa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_meijer = bin_meijer.sort_values(['dots_exten'], ascending=False)\n",
    "sort_meijer.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd96e5",
   "metadata": {},
   "source": [
    "# How to do the clustering? \n",
    "\n",
    "Three words: center of mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_locations = {'Congo':(-5.6442, 12.1375),\n",
    "                     'Cape-Town':(-33.93, 18.56),\n",
    "                    'Rio-de-la-Plata':(-33.9375, -58.5208),\n",
    "                    'Porto-Alegre':(-30.051, -51.285),\n",
    "                    'Santos':(-23.9875, -46.2958),\n",
    "                    'Paraiba':(-21.6208, -41.0375),\n",
    "                    'Itajai':(-26.9125, -48.6458),\n",
    "                    'Rio-de-Janeiro':(-23.01250, -43.32083),\n",
    "                    'Salvador':(-13.017065, -38.579832),\n",
    "                    'Recife':(-8.09, -34.88)}\n",
    "# 'Luanda':(-8.82, 13.22),\n",
    "#                      'Cuvo':(-10.87917, 13.81250),\n",
    "grid_cluster_centers = {}\n",
    "for loc in cluster_locations:\n",
    "\n",
    "    indx = nearest_coastal_cell(lat_coast, lon_coast, *cluster_locations[loc])\n",
    "    grid_cluster_centers[loc] = (lat_coast[indx], lon_coast[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7343f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = bin_meijer.sort_values(['dots_exten'], ascending=False)\n",
    "sort.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf43f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16103db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent((-70, 25, -50, 0), crs=ccrs.PlateCarree())\n",
    "ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.LAND)\n",
    "# ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.RIVERS)\n",
    "ax.gridlines(draw_labels=True, dms=False, x_inline=False, y_inline=False)\n",
    "\n",
    "M = 30\n",
    "#plt.pcolormesh(X, Y, coast)\n",
    "im = plt.scatter(sort['X_bin'][:M], sort['Y_bin'][:M], c=sort['dots_exten'][:M],\n",
    "                 s=sort['dots_exten'][:M]/5, cmap='plasma', edgecolors=None)\n",
    "\n",
    "for loc in cluster_locations:\n",
    "    x = cluster_locations[loc][1]\n",
    "    y = cluster_locations[loc][0]\n",
    "    plt.scatter(x, y, c='r')\n",
    "    \n",
    "plt.colorbar(im)\n",
    "plt.title('Meijer top 30 rivers', fontsize=16)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_of_mass(DF):\n",
    "    \n",
    "    x = DF.X_bin\n",
    "    y = DF.Y_bin\n",
    "    m = DF.dots_exten #this is so annoying\n",
    "    M = m.sum()\n",
    "    \n",
    "    return sum(m*y)/M, sum(m*x)/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rivers_per_location(DF, loc_coords, radius, binned=False, tolerance=0.1):\n",
    "    \"\"\"\n",
    "    It cluster the rivers in a square with sides 2*radius.\n",
    "    The clustering is done iteratively using the center of mass.\n",
    "    Input\n",
    "    - DF: the pandas Dataframe with data River_sources. \n",
    "    - loc_coords: tuple with the location coordinates as in (lat, lon).\n",
    "    - radius: the radius in degrees around loc_coords.\n",
    "    - tolerance: [km]\n",
    "    Returns \n",
    "    - the dataframe around loc_coords.\n",
    "    \"\"\"\n",
    "    if binned:\n",
    "        _label = '_bin'\n",
    "        \n",
    "    else:\n",
    "        _label = ''\n",
    "        \n",
    "    x_col = f'X{_label}'\n",
    "    y_col = f'Y{_label}'\n",
    "    \n",
    "    lat, lon = loc_coords\n",
    "    mask = (DF[x_col] <= lon + radius) & (DF[x_col] > lon - radius) & \\\n",
    "            (DF[y_col] <= lat + radius) & (DF[y_col] > lat - radius)\n",
    "    CM = center_of_mass(DF[mask])\n",
    "    dist = haversine_distance_two((lat,lon), CM)\n",
    "    \n",
    "    while dist > tolerance:\n",
    "        lat, lon = CM\n",
    "        mask = (DF[x_col] <= lon + radius) & (DF[x_col] > lon - radius) & \\\n",
    "                (DF[y_col] <= lat + radius) & (DF[y_col] > lat - radius)\n",
    "        CM = center_of_mass(DF[mask])\n",
    "        dist = haversine_distance_two((lat,lon), CM)\n",
    "    \n",
    "    loc_df = DF[mask]\n",
    "    p = pd.DataFrame({'p': loc_df['dots_exten']/loc_df['dots_exten'].sum()})\n",
    "    loc_df = loc_df.drop(['dots_exten'], axis=1)\n",
    "    loc_df = pd.concat([loc_df, p], axis=1)\n",
    "    loc_df.reset_index(inplace=True)\n",
    "\n",
    "    return mask, CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddceb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_mask, _cm = rivers_per_location(sort, cluster_locations['Rio-de-Janeiro'], 1, binned=True)\n",
    "print('CM', _cm)\n",
    "print('OC', cluster_locations['Rio-de-Janeiro'])\n",
    "print(haversine_distance_two(_cm, cluster_locations['Rio-de-Janeiro']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=5,nrows=2,figsize=(12,5),\n",
    "                      subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "coast_mask = np.ma.masked_equal(coast, 0)\n",
    "\n",
    "ax = np.reshape(ax, 10)\n",
    "r = 1\n",
    "\n",
    "for i, loc in enumerate(cluster_locations):\n",
    "    \n",
    "    loc_mask, loc_CM= rivers_per_location(sort, cluster_locations[loc], r, binned=True)\n",
    "    lat_BA, lon_BA = loc_CM \n",
    "    loc_df = sort[loc_mask]\n",
    "    \n",
    "    ax[i].set_extent([lon_BA-r, lon_BA+r, lat_BA-r, lat_BA+r], crs=ccrs.PlateCarree())\n",
    "    ax[i].add_feature(cfeature.OCEAN)\n",
    "    ax[i].add_feature(cfeature.LAND)\n",
    "#     ax[i].add_feature(cfeature.COASTLINE)\n",
    "    ax[i].add_feature(cfeature.RIVERS)\n",
    "    ax[i].set_title(loc)\n",
    "    ax[i].pcolormesh(X, Y, coast_mask)\n",
    "#     g1 = ax[i].gridlines(draw_labels=True, dms=False, x_inline=False, y_inline=False,\n",
    "#             color='black', linestyle='--', alpha=0.1)\n",
    "#     g1.top_labels = False\n",
    "#     g1.right_labels = False\n",
    "\n",
    "    \n",
    "    for m in loc_df.index:\n",
    "        ax[i].scatter(loc_df['X_bin'][m], loc_df['Y_bin'][m], s=loc_df['dots_exten'][m]*0.5,\n",
    "                     alpha=0.7)\n",
    "#         ax[i].scatter(cluster_locations[loc][1], cluster_locations[loc][0], c='white',\n",
    "#                       marker='s',  edgecolor='k', s=100)\n",
    "        ax[i].scatter(loc_CM[1], loc_CM[0], c='white', marker='s', edgecolor='k', s=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters(DF, N, cluster_radius=1, compute_other=False):\n",
    "    \n",
    "    release_points = {}\n",
    "    priors = {}\n",
    "\n",
    "    cluster_percent = 0\n",
    "    merged_rivers = 0\n",
    "\n",
    "    for i, loc in enumerate(cluster_locations):\n",
    "        print(loc)\n",
    "        _mask, _CM = rivers_per_location(sort, cluster_locations[loc], cluster_radius, binned=True)\n",
    "        lat_BA, lon_BA = _CM \n",
    "        loc_df = sort[_mask]\n",
    "\n",
    "        loc_percent = loc_df['dots_exten'].sum()/total_meijer\n",
    "        no_rivers = loc_df['merged_rivers'].sum()\n",
    "        merged_rivers += no_rivers\n",
    "        priors[loc] = [loc_percent, no_rivers]\n",
    "        cluster_percent += loc_df['dots_exten'].sum()/total_meijer\n",
    "        p = pd.DataFrame({'p': loc_df['dots_exten']/loc_df['dots_exten'].sum()})\n",
    "\n",
    "        loc_df = loc_df.drop(['dots_exten'], axis=1)\n",
    "        loc_df = pd.concat([loc_df, p], axis=1)\n",
    "        loc_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        release_points[loc] = loc_df.sample(n=N, replace=True, weights='p')\n",
    "\n",
    "    if compute_other:\n",
    "        priors['Other'] = [1 - cluster_percent, sa_meijer.shape[0] - merged_rivers]\n",
    "        priors = pd.DataFrame(priors).T\n",
    "\n",
    "    priors = priors.rename(columns={0:'mean', 1:'merged_rivers'})\n",
    "    \n",
    "    return release_points, priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c106398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "release_points = {}\n",
    "priors = {}\n",
    "r = 1\n",
    "N = 100000 #Number of particles realesed pre source.\n",
    "\n",
    "cluster_percent = 0\n",
    "merged_rivers = 0\n",
    "\n",
    "for i, loc in enumerate(cluster_locations):\n",
    "    print(loc)\n",
    "    _mask, _CM = rivers_per_location(sort, cluster_locations[loc], r, binned=True)\n",
    "    lat_BA, lon_BA = _CM \n",
    "    loc_df = sort[_mask]\n",
    "    \n",
    "    loc_percent = loc_df['dots_exten'].sum()/total_meijer\n",
    "    no_rivers = loc_df['merged_rivers'].sum()\n",
    "    merged_rivers += no_rivers\n",
    "    priors[loc] = [loc_percent, no_rivers]\n",
    "    cluster_percent += loc_df['dots_exten'].sum()/total_meijer\n",
    "    p = pd.DataFrame({'p': loc_df['dots_exten']/loc_df['dots_exten'].sum()})\n",
    "    \n",
    "    loc_df = loc_df.drop(['dots_exten'], axis=1)\n",
    "    loc_df = pd.concat([loc_df, p], axis=1)\n",
    "    loc_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    release_points[loc] = loc_df.sample(n=N, replace=True, weights='p')\n",
    "    \n",
    "priors['Other'] = [1 - cluster_percent, sa_meijer.shape[0] - merged_rivers]\n",
    "priors = pd.DataFrame(priors).T\n",
    "priors = priors.rename(columns={0:'mean', 1:'merged_rivers'})\n",
    "priors.to_csv('../data/analysis/river_input_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = np.load('../release_positions.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b471c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa['Congo']['X_bin'].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa['Congo'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_points['Congo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=5,nrows=2,figsize=(12,5),\n",
    "                      subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "coast_mask = np.ma.masked_equal(coast, 0)\n",
    "\n",
    "ax = np.reshape(ax, 10)\n",
    "r = 1\n",
    "\n",
    "for i, loc in enumerate(cluster_locations):\n",
    "    \n",
    "    loc_mask, loc_CM= rivers_per_location(sort, cluster_locations[loc], r, binned=True)\n",
    "    lat_BA, lon_BA = loc_CM \n",
    "#     loc_df = sort[loc_mask]\n",
    "    \n",
    "    ax[i].set_extent([lon_BA-r, lon_BA+r, lat_BA-r, lat_BA+r], crs=ccrs.PlateCarree())\n",
    "    ax[i].add_feature(cfeature.OCEAN)\n",
    "    ax[i].add_feature(cfeature.LAND)\n",
    "    ax[i].add_feature(cfeature.RIVERS)\n",
    "    ax[i].set_title(loc)\n",
    "    ax[i].pcolormesh(X, Y, coast_mask)\n",
    "    ax[i].scatter(release_points[loc]['X_bin'], release_points[loc]['Y_bin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "release_points['Recife'].hist('X_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6.5))\n",
    "wedgeprops = {'fontsize': 12}\n",
    "\n",
    "plt.pie(priors['mean'], labels=priors.index, autopct='%.1f%%',\n",
    "       shadow=True,\n",
    "       rotatelabels=True, startangle=15,textprops=wedgeprops);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad40be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
